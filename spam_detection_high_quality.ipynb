{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d84d4b8",
   "metadata": {},
   "source": [
    "\n",
    "# üìß Email/SMS Spam Detection Using Machine Learning\n",
    "\n",
    "Welcome to this comprehensive notebook where we will build a spam detection system using machine learning. This notebook is designed for clarity and learning, so every step is well-explained and beginner-friendly.\n",
    "\n",
    "**Dataset:** `spam.csv` (uploaded in the same directory)  \n",
    "**Goal:** Classify SMS or email messages as **spam** or **ham (not spam)** using a machine learning model.\n",
    "\n",
    "Let's get started! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e46bd6e",
   "metadata": {},
   "source": [
    "\n",
    "## 1Ô∏è‚É£ Importing Required Libraries\n",
    "\n",
    "Let's begin by importing all the essential libraries for data handling, text processing, model training, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43228cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad93608",
   "metadata": {},
   "source": [
    "\n",
    "## 2Ô∏è‚É£ Loading the Dataset\n",
    "\n",
    "We'll load the dataset `spam.csv`. Make sure it is in the same directory as this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c1b98",
   "metadata": {},
   "source": [
    "\n",
    "## 3Ô∏è‚É£ Data Exploration\n",
    "\n",
    "Let's check the dataset structure, inspect column names, and understand what we have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explore Data\n",
    "print(\"Columns in dataset:\", df.columns)\n",
    "df.info()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af4980",
   "metadata": {},
   "source": [
    "\n",
    "## 4Ô∏è‚É£ Data Preprocessing\n",
    "\n",
    "We'll:\n",
    "- Rename columns if necessary\n",
    "- Encode labels ('ham' ‚Üí 0, 'spam' ‚Üí 1)\n",
    "- Handle missing values (if any)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing\n",
    "# Rename columns if necessary (adjust accordingly)\n",
    "df.columns = ['label', 'text', 'Unnamed_2', 'Unnamed_3', 'Unnamed_4']  # adjust if needed\n",
    "df = df[['label', 'text']]\n",
    "\n",
    "# Encode labels\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd01e58c",
   "metadata": {},
   "source": [
    "\n",
    "## 5Ô∏è‚É£ Splitting the Data\n",
    "\n",
    "We'll split the dataset into **training** and **testing** sets to evaluate our model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685754a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split Data\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b88b2",
   "metadata": {},
   "source": [
    "\n",
    "## 6Ô∏è‚É£ Feature Extraction (TF-IDF)\n",
    "\n",
    "We'll use **TF-IDF** (Term Frequency-Inverse Document Frequency) to convert text into numerical features suitable for machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature Extraction (TF-IDF)\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF shape: {X_train_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f4f335",
   "metadata": {},
   "source": [
    "\n",
    "## 7Ô∏è‚É£ Model Training\n",
    "\n",
    "We'll train a **Logistic Regression** model to classify messages as spam or ham.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e89aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model Training\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80d5c64",
   "metadata": {},
   "source": [
    "\n",
    "## 8Ô∏è‚É£ Model Evaluation\n",
    "\n",
    "Let's evaluate the model using **accuracy** and a **classification report**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0229f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf99f0ae",
   "metadata": {},
   "source": [
    "\n",
    "## 9Ô∏è‚É£ Save the Model (Optional)\n",
    "\n",
    "Saving the trained model and vectorizer for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d11be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save Model (Optional)\n",
    "joblib.dump(model, 'spam_classifier.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "print(\"Model and vectorizer saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c8977",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Conclusion\n",
    "\n",
    "Congratulations! üéâ You've successfully built a spam detection model using machine learning. This project helps you understand data preprocessing, feature extraction, model training, and evaluation.\n",
    "\n",
    "Feel free to experiment with other models (like Naive Bayes, SVM, Random Forest) or fine-tune hyperparameters for better performance.\n",
    "\n",
    "Happy Learning! üöÄ\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
